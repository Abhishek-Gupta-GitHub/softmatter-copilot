{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Diagnostics for Confocal Microscopy Copilot\n",
    "## Physics-Based Analysis for Multi-Domain Particle Tracking\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Abhishek-Gupta-GitHub/confocal_microscopy-copilot/blob/main/notebooks/PhysicsAnalyst_Advanced_Diagnostics.ipynb)\n",
    "\n",
    "**Author:** Confocal Microscopy Copilot Team  \n",
    "**Date:** December 2025  \n",
    "**Version:** 1.0-hackathon\n",
    "\n",
    "### Scope\n",
    "This notebook extends the `PhysicsAnalyst` class with four advanced diagnostic modules:\n",
    "\n",
    "1. **Near-Wall MSD** – Detect hindered diffusion near surfaces (colloids, cells on substrate)\n",
    "2. **Cage-Relative MSD** – Identify local rearrangements and dynamic heterogeneity\n",
    "3. **Heterogeneity Metrics** – Quantify non-Gaussian dynamics and subdiffusion anomalies\n",
    "4. **Structure Functions** – Compute static structure factor and pair correlation functions\n",
    "\n",
    "**Domain Coverage:**\n",
    "- Colloidal suspensions (hard spheres, viscoelastic media, gels)\n",
    "- Biological systems (nuclear diffusion, membrane proteins, vesicles)\n",
    "- Soft matter (polymers, driven systems, active matter)\n",
    "- Near-wall phenomena (wall-induced hindrance, confinement effects)\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "If running in **Colab**, uncomment and run the setup cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COLAB SETUP (uncomment if running in Google Colab)\n",
    "# ============================================================================\n",
    "\n",
    "# !git clone https://github.com/Abhishek-Gupta-GitHub/confocal_microscopy-copilot.git\n",
    "# %cd confocal_microscopy-copilot\n",
    "# !pip install -q -r requirements.txt\n",
    "# import sys\n",
    "# sys.path.insert(0, '/content/confocal_microscopy-copilot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal, interpolate, spatial, fftpack\n",
    "from scipy.optimize import curve_fit\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting defaults\n",
    "sns.set_theme(style='whitegrid', palette='husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Structures\n",
    "\n",
    "Define domain-agnostic trajectory and physics dataclasses that will be exchanged with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Trajectory:\n",
    "    \"\"\"Universal trajectory representation.\"\"\"\n",
    "    particle_id: int\n",
    "    t: np.ndarray  # frame indices (or times)\n",
    "    x: np.ndarray  # position in um (or pixels)\n",
    "    y: np.ndarray\n",
    "    z: np.ndarray\n",
    "    confidence: Optional[np.ndarray] = None  # detection confidence [0,1] per frame\n",
    "    radius: float = 0.5  # particle radius in um\n",
    "    label: Optional[str] = None  # e.g., \"bead\", \"nucleus\", \"vesicle\"\n",
    "    \n",
    "    def length(self):\n",
    "        \"\"\"Number of points in trajectory.\"\"\"\n",
    "        return len(self.t)\n",
    "    \n",
    "    def duration(self):\n",
    "        \"\"\"Total duration in frames or time units.\"\"\"\n",
    "        return self.t[-1] - self.t[0]\n",
    "    \n",
    "    def positions_3d(self):\n",
    "        \"\"\"Return (N, 3) array of positions.\"\"\"\n",
    "        return np.column_stack([self.x, self.y, self.z])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MSDAnalysis:\n",
    "    \"\"\"Mean square displacement metrics.\"\"\"\n",
    "    lag_times: List[float]  # tau values\n",
    "    msd_bulk: List[float]  # overall MSD\n",
    "    msd_wall: Optional[List[float]] = None  # near-wall MSD\n",
    "    msd_cage: Optional[List[float]] = None  # cage-relative MSD\n",
    "    diffusion_coeff: Optional[float] = None  # D from linear fit\n",
    "    anomaly_exponent: Optional[float] = None  # alpha: MSD ~ t^alpha\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HeterogeneityMetrics:\n",
    "    \"\"\"Non-Gaussian and heterogeneity descriptors.\"\"\"\n",
    "    alpha2_max: Optional[float] = None  # peak non-Gaussian parameter\n",
    "    alpha2_tau_peak: Optional[float] = None  # lag time at peak alpha2\n",
    "    msd_distribution_std: Optional[float] = None  # std of MSD across particles\n",
    "    msd_distribution_mean: Optional[float] = None  # mean MSD\n",
    "    subdiffusion_detected: bool = False  # true if alpha < 1\n",
    "    superdiffusion_detected: bool = False  # true if alpha > 1\n",
    "    dynamic_susceptibility: Optional[float] = None  # variance-based measure\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StructureAnalysis:\n",
    "    \"\"\"Static structure and correlation functions.\"\"\"\n",
    "    q_values: List[float]  # wave vectors\n",
    "    structure_factor: List[float]  # S(q) static structure factor\n",
    "    pair_correlation: Optional[List[float]] = None  # g(r) radial distribution\n",
    "    distances: Optional[List[float]] = None  # r values for g(r)\n",
    "    density: Optional[float] = None  # particle density\n",
    "    clustering_detected: bool = False  # true if S(0) >> 1\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "\nprint(\"✓ Data structures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Core Diagnostic Module – PhysicsAnalyst\n",
    "\n",
    "Comprehensive implementation of all four diagnostic categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsAnalyst:\n",
    "    \"\"\"\n",
    "    Multi-domain physics analyzer for confocal microscopy trajectories.\n",
    "    Computes MSD variants, heterogeneity metrics, and structure functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dt: float = 1.0,  # time per frame (ms, s, etc.)\n",
    "                 px_to_um: float = 1.0,  # pixel to micrometer conversion\n",
    "                 wall_z_threshold: float = 2.0):  # wall proximity threshold (um)\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dt : float\n",
    "            Time interval per frame (units: ms, s, etc.). Used for physical time axes.\n",
    "        px_to_um : float\n",
    "            Pixel-to-micrometer conversion factor.\n",
    "        wall_z_threshold : float\n",
    "            Distance threshold below which particles are considered \"near-wall\".\n",
    "        \"\"\"\n",
    "        self.dt = dt\n",
    "        self.px_to_um = px_to_um\n",
    "        self.wall_z_threshold = wall_z_threshold\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CORE MSD COMPUTATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_msd(self, trajectory: Trajectory, \n",
    "                   max_lag_frames: Optional[int] = None,\n",
    "                   stride: int = 1) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute mean square displacement.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectory : Trajectory\n",
    "            Single particle trajectory.\n",
    "        max_lag_frames : int, optional\n",
    "            Maximum lag time in frames. Default: 1/4 of trajectory length.\n",
    "        stride : int\n",
    "            Compute MSD at every stride-th lag time (reduce computation).\n",
    "        \n",
    "        Returns\n",
        "        -------\n",
    "        lag_times : ndarray\n",
    "            Lag times in physical units (dt * frames).\n",
    "        msd : ndarray\n",
    "            Mean square displacement in (um)^2.\n",
    "        \"\"\"\n",
    "        pos = trajectory.positions_3d() * self.px_to_um\n",
    "        N = len(pos)\n",
    "        \n",
    "        if max_lag_frames is None:\n",
    "            max_lag_frames = max(N // 4, 1)\n",
    "        \n",
    "        max_lag_frames = min(max_lag_frames, N - 1)\n",
    "        lag_frames = np.arange(0, max_lag_frames + 1, stride)\n",
    "        msd = np.zeros(len(lag_frames))\n",
    "        \n",
    "        for i, tau_frame in enumerate(lag_frames):\n",
    "            if tau_frame == 0:\n",
    "                msd[i] = 0.0\n",
    "            else:\n",
    "                disp = pos[tau_frame:] - pos[:-tau_frame]\n",
    "                msd[i] = np.mean(np.sum(disp**2, axis=1))\n",
    "        \n",
    "        lag_times = lag_frames * self.dt\n",
    "        return lag_times, msd\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. NEAR-WALL MSD\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_wall_proximity_mask(self, trajectory: Trajectory) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify frames where particle is near the wall (bottom substrate).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mask : ndarray of bool\n",
    "            True where z < wall_z_threshold.\n",
    "        \"\"\"\n",
    "        z_scaled = trajectory.z * self.px_to_um\n",
    "        return z_scaled < self.wall_z_threshold\n",
    "    \n",
    "    def compute_near_wall_msd(self, trajectory: Trajectory,\n",
    "                              max_lag_frames: Optional[int] = None,\n",
    "                              stride: int = 1) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute MSD for trajectories near the wall (z < threshold).\n",
    "        \n",
    "        Compare with bulk MSD to detect wall-induced hindrance.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lag_times : ndarray\n",
    "            Lag times in physical units.\n",
    "        msd_wall : ndarray\n",
    "            MSD for near-wall segments.\n",
    "        msd_bulk : ndarray\n",
    "            MSD for bulk (far-wall) segments.\n",
    "        \"\"\"\n",
    "        pos = trajectory.positions_3d() * self.px_to_um\n",
    "        wall_mask = self.compute_wall_proximity_mask(trajectory)\n",
    "        \n",
    "        N = len(pos)\n",
    "        if max_lag_frames is None:\n",
    "            max_lag_frames = max(N // 4, 1)\n",
    "        \n",
    "        max_lag_frames = min(max_lag_frames, N - 1)\n",
    "        lag_frames = np.arange(0, max_lag_frames + 1, stride)\n",
    "        \n",
    "        msd_wall = np.zeros(len(lag_frames))\n",
    "        msd_bulk = np.zeros(len(lag_frames))\n",
    "        counts_wall = np.zeros(len(lag_frames))\n",
    "        counts_bulk = np.zeros(len(lag_frames))\n",
    "        \n",
    "        for i, tau_frame in enumerate(lag_frames):\n",
    "            if tau_frame == 0:\n",
    "                msd_wall[i] = 0.0\n",
    "                msd_bulk[i] = 0.0\n",
    "            else:\n",
    "                disp = pos[tau_frame:] - pos[:-tau_frame]\n",
    "                displacements_sq = np.sum(disp**2, axis=1)\n",
    "                \n",
    "                # Condition on wall proximity at start of interval\n",
    "                wall_starts = wall_mask[:-tau_frame]\n",
    "                bulk_starts = ~wall_mask[:-tau_frame]\n",
    "                \n",
    "                if wall_starts.sum() > 0:\n",
    "                    msd_wall[i] = np.mean(displacements_sq[wall_starts])\n",
    "                    counts_wall[i] = wall_starts.sum()\n",
    "                \n",
    "                if bulk_starts.sum() > 0:\n",
    "                    msd_bulk[i] = np.mean(displacements_sq[bulk_starts])\n",
    "                    counts_bulk[i] = bulk_starts.sum()\n",
    "        \n",
    "        lag_times = lag_frames * self.dt\n",
    "        return lag_times, msd_wall, msd_bulk\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. CAGE-RELATIVE MSD\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_cage_relative_msd(self, trajectories: List[Trajectory],\n",
    "                                  reference_traj_idx: int,\n",
    "                                  cage_radius: float = 5.0,  # um\n",
    "                                  max_lag_frames: Optional[int] = None,\n",
    "                                  stride: int = 1) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute cage-relative MSD for a single particle.\n",
    "        \n",
    "        This subtracts the center-of-mass motion of the local neighborhood,\n",
    "        revealing rearrangements vs. affine (bulk) motion.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectories : List[Trajectory]\n",
    "            All trajectories in the system.\n",
    "        reference_traj_idx : int\n",
    "            Index of particle for which to compute cage-relative MSD.\n",
    "        cage_radius : float\n",
    "            Neighborhood radius for defining the cage (um).\n",
    "        max_lag_frames : int, optional\n",
    "            Maximum lag time in frames.\n",
    "        stride : int\n",
    "            Stride for lag times.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lag_times : ndarray\n",
    "            Lag times.\n",
    "        msd_cage : ndarray\n",
    "            Cage-relative MSD.\n",
    "        msd_bulk : ndarray\n",
    "            Bulk (non-relative) MSD for reference.\n",
    "        \"\"\"\n",
    "        ref_traj = trajectories[reference_traj_idx]\n",
    "        ref_pos = ref_traj.positions_3d() * self.px_to_um\n",
    "        N = len(ref_pos)\n",
    "        \n",
    "        if max_lag_frames is None:\n",
    "            max_lag_frames = max(N // 4, 1)\n",
    "        \n",
    "        # Identify cage neighbors (within cage_radius at t=0)\n",
    "        t0_ref_pos = ref_pos[0]\n",
    "        cage_neighbors = []\n",
    "        \n",
    "        for j, traj in enumerate(trajectories):\n",
    "            if j == reference_traj_idx:\n",
    "                continue\n",
    "            other_pos = traj.positions_3d() * self.px_to_um\n",
    "            dist_to_ref = np.linalg.norm(other_pos[0] - t0_ref_pos)\n",
    "            if dist_to_ref < cage_radius:\n",
    "                cage_neighbors.append(j)\n",
    "        \n",
    "        if not cage_neighbors:\n",
    "            # No neighbors; fall back to bulk MSD\n",
    "            lag_times, msd_bulk = self.compute_msd(ref_traj, max_lag_frames, stride)\n",
    "            return lag_times, msd_bulk.copy(), msd_bulk.copy()\n",
    "        \n",
    "        # Build neighbor position matrix: (N_frames, N_neighbors, 3)\n",
    "        neighbor_positions = np.stack(\n",
    "            [trajectories[j].positions_3d() * self.px_to_um for j in cage_neighbors],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Compute COM of cage at each time step\n",
    "        cage_com = np.mean(neighbor_positions, axis=1)  # (N_frames, 3)\n",
    "        \n",
    "        # Compute cage-relative position (reference particle - cage COM)\n",
    "        rel_pos = ref_pos - cage_com\n",
    "        \n",
    "        max_lag_frames = min(max_lag_frames, N - 1)\n",
    "        lag_frames = np.arange(0, max_lag_frames + 1, stride)\n",
    "        \n",
    "        msd_cage = np.zeros(len(lag_frames))\n",
    "        msd_bulk = np.zeros(len(lag_frames))\n",
    "        \n",
    "        for i, tau_frame in enumerate(lag_frames):\n",
    "            if tau_frame == 0:\n",
    "                msd_cage[i] = 0.0\n",
    "                msd_bulk[i] = 0.0\n",
    "            else:\n",
    "                # Bulk MSD\n",
    "                disp_bulk = ref_pos[tau_frame:] - ref_pos[:-tau_frame]\n",
    "                msd_bulk[i] = np.mean(np.sum(disp_bulk**2, axis=1))\n",
    "                \n",
    "                # Cage-relative MSD\n",
    "                disp_rel = rel_pos[tau_frame:] - rel_pos[:-tau_frame]\n",
    "                msd_cage[i] = np.mean(np.sum(disp_rel**2, axis=1))\n",
    "        \n",
    "        lag_times = lag_frames * self.dt\n",
    "        return lag_times, msd_cage, msd_bulk\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. HETEROGENEITY METRICS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def fit_msd_power_law(self, lag_times: np.ndarray, msd: np.ndarray,\n",
    "                          window_fraction: float = 0.3) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Fit MSD ~ t^alpha in linear region to extract anomaly exponent.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lag_times : ndarray\n",
    "            Lag times.\n",
    "        msd : ndarray\n",
    "            Mean square displacements.\n",
    "        window_fraction : float\n",
    "            Use this fraction of data in linear regime (default: first 30%).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        alpha : float\n",
    "            Anomaly exponent (1=Brownian, <1=subdiffusion, >1=superdiffusion).\n",
    "        D_alpha : float\n",
    "            Generalized diffusion coefficient.\n",
    "        \"\"\"\n",
    "        # Use early-time window to avoid noise and saturation\n",
    "        n_points = max(int(len(lag_times) * window_fraction), 2)\n",
    "        \n",
    "        # Skip lag=0\n",
    "        idx = slice(1, n_points + 1)\n",
    "        \n",
    "        log_tau = np.log(lag_times[idx])\n",
    "        log_msd = np.log(np.maximum(msd[idx], 1e-10))\n",
    "        \n",
    "        # Linear fit in log-log space\n",
    "        coeffs = np.polyfit(log_tau, log_msd, 1)\n",
    "        alpha = coeffs[0]\n",
    "        D_alpha = np.exp(coeffs[1]) / (2 * 3)  # generalized D (3D)\n",
    "        \n",
    "        return alpha, D_alpha\n",
    "    \n",
    "    def compute_non_gaussian_parameter(self, trajectories: List[Trajectory],\n",
    "                                       max_lag_frames: Optional[int] = None,\n",
    "                                       stride: int = 1) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute non-Gaussian parameter α2(τ) across particle ensemble.\n",
    "        \n",
    "        α2(τ) = <r^4(τ)> / (3 * <r^2(τ)>^2) - 1\n",
    "        \n",
    "        α2 ≈ 0 for Gaussian displacements, α2 > 0 indicates non-Gaussian tails.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectories : List[Trajectory]\n",
    "            All trajectories.\n",
    "        max_lag_frames : int, optional\n",
    "            Maximum lag time.\n",
    "        stride : int\n",
    "            Stride in lag times.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lag_times : ndarray\n",
    "            Lag times.\n",
    "        alpha2 : ndarray\n",
    "            Non-Gaussian parameter vs lag time.\n",
    "        \"\"\"\n",
    "        if not trajectories:\n",
    "            return np.array([0.0]), np.array([0.0])\n",
    "        \n",
    "        N_frames = max([len(t.t) for t in trajectories])\n",
    "        if max_lag_frames is None:\n",
    "            max_lag_frames = max(N_frames // 4, 1)\n",
    "        \n",
    "        max_lag_frames = min(max_lag_frames, N_frames - 1)\n",
    "        lag_frames = np.arange(0, max_lag_frames + 1, stride)\n",
    "        alpha2 = np.zeros(len(lag_frames))\n",
    "        \n",
    "        for i, tau_frame in enumerate(lag_frames):\n",
    "            if tau_frame == 0:\n",
    "                alpha2[i] = 0.0\n",
    "                continue\n",
    "            \n",
    "            r2_list = []\n",
    "            r4_list = []\n",
    "            \n",
    "            for traj in trajectories:\n",
    "                if len(traj.t) <= tau_frame:\n",
    "                    continue\n",
    "                \n",
    "                pos = traj.positions_3d() * self.px_to_um\n",
    "                disp = pos[tau_frame:] - pos[:-tau_frame]\n",
    "                r2 = np.sum(disp**2, axis=1)\n",
    "                r2_list.extend(r2)\n",
    "                r4_list.extend(r2**2)\n",
    "            \n",
    "            if len(r2_list) > 1:\n",
    "                r2_mean = np.mean(r2_list)\n",
    "                r4_mean = np.mean(r4_list)\n",
    "                alpha2[i] = (r4_mean / (3 * r2_mean**2)) - 1.0 if r2_mean > 0 else 0.0\n",
    "            else:\n",
    "                alpha2[i] = 0.0\n",
    "        \n",
    "        lag_times = lag_frames * self.dt\n",
    "        return lag_times, alpha2\n",
    "    \n",
    "    def compute_heterogeneity_metrics(self, trajectories: List[Trajectory],\n",
    "                                      max_lag_frames: Optional[int] = None) -> HeterogeneityMetrics:\n",
    "        \"\"\"\n",
    "        Compute full heterogeneity analysis across trajectory ensemble.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        HeterogeneityMetrics\n",
    "            Dataclass with all heterogeneity descriptors.\n",
    "        \"\"\"\n",
    "        if not trajectories:\n",
    "            return HeterogeneityMetrics()\n",
    "        \n",
    "        # Compute per-particle anomaly exponents\n",
    "        alphas = []\n",
    "        msd_at_long_tau = []\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            lag_times, msd = self.compute_msd(traj, max_lag_frames)\n",
    "            if len(lag_times) > 1:\n",
    "                alpha, _ = self.fit_msd_power_law(lag_times, msd, window_fraction=0.3)\n",
    "                alphas.append(alpha)\n",
    "                msd_at_long_tau.append(msd[-1])  # MSD at longest lag\n",
    "        \n",
    "        # Non-Gaussian parameter\n",
    "        lag_times, alpha2_array = self.compute_non_gaussian_parameter(trajectories, max_lag_frames)\n",
    "        alpha2_max = float(np.max(alpha2_array)) if len(alpha2_array) > 0 else None\n",
    "        alpha2_tau_peak = float(lag_times[np.argmax(alpha2_array)]) if len(alpha2_array) > 0 else None\n",
    "        \n",
    "        # Distribution statistics\n",
    "        msd_mean = float(np.mean(msd_at_long_tau)) if msd_at_long_tau else None\n",
    "        msd_std = float(np.std(msd_at_long_tau)) if msd_at_long_tau else None\n",
    "        \n",
    "        # Subdiffusion/superdiffusion detection\n",
    "        mean_alpha = float(np.mean(alphas)) if alphas else 1.0\n",
    "        subdiffusion = mean_alpha < 0.9\n",
    "        superdiffusion = mean_alpha > 1.1\n",
    "        \n",
    "        # Dynamic susceptibility (as proxy for heterogeneity)\n",
    "        dynamic_susceptibility = msd_std / msd_mean if (msd_mean and msd_std) else None\n",
    "        \n",
    "        return HeterogeneityMetrics(\n",
    "            alpha2_max=alpha2_max,\n",
    "            alpha2_tau_peak=alpha2_tau_peak,\n",
    "            msd_distribution_std=msd_std,\n",
    "            msd_distribution_mean=msd_mean,\n",
    "            subdiffusion_detected=subdiffusion,\n",
    "            superdiffusion_detected=superdiffusion,\n",
    "            dynamic_susceptibility=dynamic_susceptibility\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. STRUCTURE FUNCTIONS\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_static_structure_factor(self, trajectories: List[Trajectory],\n",
    "                                       time_window_fraction: float = 0.5,\n",
    "                                       n_q_bins: int = 20) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute static structure factor S(q) from spatial positions.\n",
    "        \n",
    "        S(q) = 1 + (1/N) * |sum_j exp(i q · r_j)|^2\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectories : List[Trajectory]\n",
    "            All trajectories.\n",
    "        time_window_fraction : float\n",
    "            Use last fraction of trajectory for averaging.\n",
    "        n_q_bins : int\n",
    "            Number of q-vector magnitudes.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        q_values : ndarray\n",
    "            Wave vector magnitudes (1/um).\n",
    "        S_q : ndarray\n",
    "            Structure factor S(q).\n",
    "        \"\"\"\n",
    "        if not trajectories:\n",
    "            return np.array([0.0]), np.array([0.0])\n",
    "        \n",
    "        # Collect positions from late-time window\n",
    "        all_positions = []\n",
    "        for traj in trajectories:\n",
    "            pos = traj.positions_3d() * self.px_to_um\n",
    "            t_start = int(len(pos) * (1 - time_window_fraction))\n",
    "            all_positions.append(np.mean(pos[t_start:], axis=0))  # time-averaged position\n",
    "        \n",
    "        positions = np.array(all_positions)  # (N_particles, 3)\n",
    "        N = len(positions)\n",
    "        \n",
    "        if N < 2:\n",
    "            return np.array([0.0]), np.array([1.0])\n",
    "        \n",
    "        # Define q-space grid\n",
    "        # Typical q range: 2*pi / L where L ~ system size\n",
    "        system_size = np.max(np.ptp(positions, axis=0))\n",
    "        max_q = 2 * np.pi / (system_size / 10)  # sample ~10 wavelengths\n",
    "        q_values = np.linspace(0.1, max_q, n_q_bins)\n",
    "        \n",
    "        S_q = np.ones_like(q_values)\n",
    "        \n",
    "        for i, q_mag in enumerate(q_values):\n",
    "            # Random q-vector direction for isotropic average\n",
    "            theta = np.random.rand() * 2 * np.pi\n",
    "            phi = np.random.rand() * np.pi\n",
    "            q_vec = q_mag * np.array([np.sin(phi) * np.cos(theta),\n",
    "                                       np.sin(phi) * np.sin(theta),\n",
    "                                       np.cos(phi)])\n",
    "            \n",
    "            # Compute |sum exp(i q·r)|^2\n",
    "            phase = np.dot(positions, q_vec)\n",
    "            sum_exp = np.sum(np.exp(1j * phase))\n",
    "            S_q[i] = 1.0 + (np.abs(sum_exp)**2 / N)\n",
    "        \n",
    "        return q_values, S_q\n",
    "    \n",
    "    def compute_pair_correlation(self, trajectories: List[Trajectory],\n",
    "                                time_window_fraction: float = 0.5,\n",
    "                                n_r_bins: int = 30) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute radial distribution function g(r).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectories : List[Trajectory]\n",
    "            All trajectories.\n",
    "        time_window_fraction : float\n",
    "            Use last fraction of trajectory for averaging.\n",
    "        n_r_bins : int\n",
    "            Number of radial bins.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        r_values : ndarray\n",
    "            Distances (um).\n",
    "        g_r : ndarray\n",
    "            Radial distribution function.\n",
    "        \"\"\"\n",
    "        if not trajectories:\n",
    "            return np.array([0.0]), np.array([0.0])\n",
    "        \n",
    "        # Collect positions from late-time window\n",
    "        all_positions = []\n",
    "        for traj in trajectories:\n",
    "            pos = traj.positions_3d() * self.px_to_um\n",
    "            t_start = int(len(pos) * (1 - time_window_fraction))\n",
    "            all_positions.append(np.mean(pos[t_start:], axis=0))\n",
    "        \n",
    "        positions = np.array(all_positions)\n",
    "        N = len(positions)\n",
    "        \n",
    "        if N < 2:\n",
    "            return np.array([0.0]), np.array([0.0])\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        distances = spatial.distance.pdist(positions, metric='euclidean')\n",
    "        \n",
    "        # Bin distances\n",
    "        r_max = np.max(distances)\n",
    "        r_bins = np.linspace(0, r_max, n_r_bins)\n",
    "        g_r, _ = np.histogram(distances, bins=r_bins, density=False)\n",
    "        \n",
    "        # Normalize by bin volume and density\n",
    "        dr = r_bins[1] - r_bins[0] if len(r_bins) > 1 else 1.0\n",
    "        r_centers = (r_bins[:-1] + r_bins[1:]) / 2\n",
    "        bin_volume = 4 * np.pi * r_centers**2 * dr\n",
    "        \n",
    "        # Expected count for random distribution\n",
    "        density = N / (np.ptp(positions, axis=0).prod() if np.all(np.ptp(positions, axis=0) > 0) else 1.0)\n",
    "        expected_count = bin_volume * density * (N - 1) / 2  # pairs\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        g_r_normalized = np.where(expected_count > 0, g_r / expected_count, 0.0)\n",
    "        \n",
    "        return r_centers, g_r_normalized\n",
    "    \n",
    "    def compute_structure_analysis(self, trajectories: List[Trajectory]) -> StructureAnalysis:\n",
    "        \"\"\"\n",
    "        Compute full structure analysis (S(q) and g(r)).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        StructureAnalysis\n",
    "            Dataclass with structure factor and pair correlation.\n",
    "        \"\"\"\n",
    "        q_vals, S_q = self.compute_static_structure_factor(trajectories)\n",
    "        r_vals, g_r = self.compute_pair_correlation(trajectories)\n",
    "        \n",
    "        density = len(trajectories) / (np.mean([np.ptp(t.positions_3d(), axis=0).prod() for t in trajectories]) * (self.px_to_um**3) + 1e-10)\n",
    "        \n",
    "        clustering = S_q[0] > 1.5 if len(S_q) > 0 else False  # S(0) >> 1 indicates clustering\n",
    "        \n",
    "        return StructureAnalysis(\n",
    "            q_values=q_vals.tolist(),\n",
    "            structure_factor=S_q.tolist(),\n",
    "            pair_correlation=g_r.tolist(),\n",
    "            distances=r_vals.tolist(),\n",
    "            density=float(density),\n",
    "            clustering_detected=clustering\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # AGGREGATED SUMMARY (JSON for LLM)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def summarize_physics(self, trajectories: List[Trajectory],\n",
    "                          domain: str = \"general\") -> Dict:\n",
    "        \"\"\"\n",
    "        Generate comprehensive physics summary as JSON for LLM + UI.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        trajectories : List[Trajectory]\n",
    "            All particle trajectories.\n",
    "        domain : str\n",
    "            Domain context: \"colloidal\", \"cellular\", \"polymer\", or \"general\".\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Comprehensive JSON summary with all metrics.\n",
    "        \"\"\"\n",
    "        if not trajectories:\n",
    "            return {\"error\": \"No trajectories provided\"}\n",
    "        \n",
    "        # 1. Bulk MSD\n",
    "        ref_traj = trajectories[0]\n",
    "        lag_times, msd_bulk = self.compute_msd(ref_traj)\n",
    "        alpha_bulk, D_bulk = self.fit_msd_power_law(lag_times, msd_bulk)\n",
    "        \n",
    "        # 2. Near-wall MSD (if applicable)\n",
    "        lag_times_wall, msd_wall, msd_bulk_full = self.compute_near_wall_msd(ref_traj)\n",
    "        alpha_wall, D_wall = self.fit_msd_power_law(lag_times_wall, np.maximum(msd_wall, 1e-10))\n",
    "        \n",
    "        # 3. Cage-relative MSD (if multiple particles)\n",
    "        if len(trajectories) > 1:\n",
    "            lag_times_cage, msd_cage, msd_bulk_cage = self.compute_cage_relative_msd(\n",
    "                trajectories, reference_traj_idx=0\n",
    "            )\n",
    "            alpha_cage, D_cage = self.fit_msd_power_law(lag_times_cage, msd_cage)\n",
    "        else:\n",
    "            lag_times_cage, msd_cage, msd_bulk_cage = lag_times, msd_bulk.copy(), msd_bulk.copy()\n",
    "            alpha_cage, D_cage = alpha_bulk, D_bulk\n",
    "        \n",
    "        # 4. Heterogeneity\n",
    "        hetero = self.compute_heterogeneity_metrics(trajectories)\n",
    "        \n",
    "        # 5. Structure\n",
    "        struct = self.compute_structure_analysis(trajectories)\n",
    "        \n",
    "        # Compile JSON\n",
    "        summary = {\n",
    "            \"metadata\": {\n",
    "                \"domain\": domain,\n",
    "                \"n_trajectories\": len(trajectories),\n",
    "                \"mean_trajectory_length\": float(np.mean([len(t.t) for t in trajectories])),\n",
    "                \"dt_physical_units\": self.dt,\n",
    "                \"px_to_um_conversion\": self.px_to_um,\n",
    "            },\n",
    "            \"msd_analysis\": {\n",
    "                \"bulk\": {\n",
    "                    \"lag_times\": lag_times.tolist(),\n",
    "                    \"msd_values\": msd_bulk.tolist(),\n",
    "                    \"anomaly_exponent_alpha\": float(alpha_bulk),\n",
    "                    \"diffusion_coefficient\": float(D_bulk),\n",
    "                    \"interpretation\": self._interpret_msd_exponent(alpha_bulk)\n",
    "                },\n",
    "                \"near_wall\": {\n",
    "                    \"lag_times\": lag_times_wall.tolist(),\n",
    "                    \"msd_wall\": msd_wall.tolist(),\n",
    "                    \"msd_bulk\": msd_bulk_full.tolist(),\n",
    "                    \"wall_hindrance_ratio\": float(np.mean(msd_bulk_full[1:] / (msd_wall[1:] + 1e-10))) if len(msd_wall) > 1 else 1.0,\n",
    "                    \"anomaly_exponent_wall\": float(alpha_wall),\n",
    "                },\n",
    "                \"cage_relative\": {\n",
    "                    \"lag_times\": lag_times_cage.tolist(),\n",
    "                    \"msd_cage\": msd_cage.tolist(),\n",
    "                    \"msd_reference\": msd_bulk_cage.tolist(),\n",
    "                    \"anomaly_exponent_cage\": float(alpha_cage),\n",
    "                }\n",
    "            },\n",
    "            \"heterogeneity\": asdict(hetero),\n",
    "            \"structure\": asdict(struct),\n",
    "            \"flags_and_anomalies\": self._generate_flags(alpha_bulk, hetero, struct, domain)\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _interpret_msd_exponent(self, alpha: float) -> str:\n",
    "        \"\"\"Interpret MSD exponent value.\"\"\"\n",
    "        if alpha < 0.8:\n",
    "            return \"Strong subdiffusion (possibly caged/glassy)\"\n",
    "        elif alpha < 1.0:\n",
    "            return \"Subdiffusion (viscoelastic or confined)\"\n",
    "        elif 0.95 < alpha < 1.05:\n",
    "            return \"Brownian diffusion (normal)\"\n",
    "        elif alpha <= 1.2:\n",
    "            return \"Slight superdiffusion (transient dynamics)\"\n",
    "        else:\n",
    "            return \"Strong superdiffusion (active or ballistic)\"\n",
    "    \n",
    "    def _generate_flags(self, alpha: float, hetero: HeterogeneityMetrics, \n",
    "                       struct: StructureAnalysis, domain: str) -> List[str]:\n",
    "        \"\"\"Generate domain-aware flags and anomalies.\"\"\"\n",
    "        flags = []\n",
    "        \n",
    "        # MSD-based flags\n",
    "        if hetero.subdiffusion_detected:\n",
    "            flags.append(f\"subdiffusion_detected: alpha < 0.9 (viscoelasticity or confinement)\")\n",
    "        if hetero.superdiffusion_detected:\n",
    "            flags.append(f\"superdiffusion_detected: alpha > 1.1 (active transport or drift)\")\n",
    "        \n",
    "        # Heterogeneity flags\n",
    "        if hetero.alpha2_max is not None and hetero.alpha2_max > 0.1:\n",
    "            flags.append(f\"non_gaussian_dynamics: alpha2_max = {hetero.alpha2_max:.3f} at tau = {hetero.alpha2_tau_peak}\")\n",
    "        \n",
    "        if hetero.dynamic_susceptibility is not None and hetero.dynamic_susceptibility > 0.3:\n",
    "            flags.append(f\"strong_heterogeneity: MSD variance/mean ratio = {hetero.dynamic_susceptibility:.2f}\")\n",
    "        \n",
    "        # Structure flags\n",
    "        if struct.clustering_detected:\n",
    "            flags.append(f\"spatial_clustering: S(0) = {struct.structure_factor[0]:.2f} (non-random distribution)\")\n",
    "        \n",
    "        # Domain-specific flags\n",
    "        if domain == \"colloidal\" and hetero.subdiffusion_detected:\n",
    "            flags.append(\"colloidal_context: subdiffusion may indicate gel formation or jamming\")\n",
    "        elif domain == \"cellular\" and struct.clustering_detected:\n",
    "            flags.append(\"cellular_context: clustering may indicate organelle co-localization\")\n",
    "        elif domain == \"polymer\" and hetero.alpha2_max is not None and hetero.alpha2_max > 0.2:\n",
    "            flags.append(\"polymer_context: non-Gaussian dynamics consistent with polymer chain dynamics\")\n",
    "        \n",
    "        return flags if flags else [\"system_behaves_normally_no_anomalies_detected\"]\n",
    "\n",
    "\n",
    "print(\"✓ PhysicsAnalyst class defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Demonstration on Synthetic Data\n",
    "\n",
    "Generate realistic synthetic trajectories and run full diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SYNTHETIC DATA GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_brownian_trajectory(n_frames: int, dt: float = 0.1, \n",
    "                                 diffusion_coeff: float = 1.0,\n",
    "                                 start_pos: tuple = (0, 0, 0)) -> Trajectory:\n",
    "    \"\"\"\n",
    "    Generate Brownian motion trajectory.\n",
    "    \n",
    "    MSD(t) = 6 * D * t (for 3D)\n",
    "    \"\"\"\n",
    "    sigma = np.sqrt(2 * diffusion_coeff * dt)\n",
    "    steps = np.random.normal(0, sigma, (n_frames, 3))\n",
    "    pos = np.cumsum(steps, axis=0) + np.array(start_pos)\n",
    "    \n",
    "    return Trajectory(\n",
    "        particle_id=0,\n",
    "        t=np.arange(n_frames),\n",
    "        x=pos[:, 0],\n",
    "        y=pos[:, 1],\n",
    "        z=pos[:, 2],\n",
    "        radius=0.5,\n",
    "        label=\"bead\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_subdiffusive_trajectory(n_frames: int, dt: float = 0.1,\n",
    "                                      alpha: float = 0.7, start_pos: tuple = (0, 0, 0)) -> Trajectory:\n",
    "    \"\"\"\n",
    "    Generate subdiffusive (fractional Brownian motion) trajectory.\n",
    "    MSD(t) ~ t^alpha with alpha < 1.\n",
    "    \"\"\"\n",
    "    # Simplified: use correlated steps\n",
    "    steps = np.random.normal(0, 1.0, (n_frames, 3))\n",
    "    \n",
    "    # Apply temporal correlations to reduce alpha\n",
    "    for i in range(1, n_frames):\n",
    "        steps[i] = (1 - alpha) * steps[i] + alpha * steps[i - 1]\n",
    "    \n",
    "    pos = np.cumsum(steps * np.sqrt(dt), axis=0) + np.array(start_pos)\n",
    "    \n",
    "    return Trajectory(\n",
    "        particle_id=0,\n",
    "        t=np.arange(n_frames),\n",
    "        x=pos[:, 0],\n",
    "        y=pos[:, 1],\n",
    "        z=pos[:, 2],\n",
    "        radius=0.5,\n",
    "        label=\"confined_particle\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_ensemble(n_particles: int, n_frames: int, dt: float = 0.1,\n",
    "                     domain: str = \"colloidal\") -> List[Trajectory]:\n",
    "    \"\"\"\n",
    "    Generate an ensemble of particles with domain-specific properties.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    domain : str\n",
    "        \"colloidal\", \"cellular\", \"polymer\", or \"mixed_heterogeneous\"\n",
    "    \"\"\"\n",
    "    trajectories = []\n",
    "    \n",
    "    if domain == \"colloidal\":\n",
    "        # Hard sphere colloids: Brownian motion\n",
    "        for i in range(n_particles):\n",
    "            start_pos = (np.random.uniform(-10, 10), \n",
    "                         np.random.uniform(-10, 10), \n",
    "                         np.random.uniform(2, 8))\n",
    "            traj = generate_brownian_trajectory(n_frames, dt=dt, diffusion_coeff=1.0, start_pos=start_pos)\n",
    "            traj.particle_id = i\n",
    "            traj.label = \"colloidal_bead\"\n",
    "            trajectories.append(traj)\n",
    "    \n",
    "    elif domain == \"cellular\":\n",
    "        # Cells/vesicles: constrained + occasional jumps (active transport)\n",
    "        for i in range(n_particles):\n",
    "            start_pos = (np.random.uniform(-5, 5),\n",
    "                         np.random.uniform(-5, 5),\n",
    "                         np.random.uniform(1, 4))\n",
    "            traj = generate_subdiffusive_trajectory(n_frames, dt=dt, alpha=0.8, start_pos=start_pos)\n",
    "            traj.particle_id = i\n",
    "            traj.label = \"nucleus\" if i % 2 == 0 else \"vesicle\"\n",
    "            trajectories.append(traj)\n",
    "    \n",
    "    elif domain == \"polymer\":\n",
    "        # Polymers: strong subdiffusion + highly heterogeneous\n",
    "        for i in range(n_particles):\n",
    "            alpha = np.random.uniform(0.5, 0.8)  # variable alpha\n",
    "            start_pos = (np.random.uniform(-3, 3),\n",
    "                         np.random.uniform(-3, 3),\n",
    "                         np.random.uniform(0.5, 3))\n",
    "            traj = generate_subdiffusive_trajectory(n_frames, dt=dt, alpha=alpha, start_pos=start_pos)\n",
    "            traj.particle_id = i\n",
    "            traj.label = \"polymer_bead\"\n",
    "            trajectories.append(traj)\n",
    "    \n",
    "    elif domain == \"mixed_heterogeneous\":\n",
    "        # Mixture: some Brownian, some subdiffusive\n",
    "        for i in range(n_particles):\n",
    "            start_pos = (np.random.uniform(-8, 8),\n",
    "                         np.random.uniform(-8, 8),\n",
    "                         np.random.uniform(1, 6))\n",
    "            if i < n_particles // 2:\n",
    "                traj = generate_brownian_trajectory(n_frames, dt=dt, diffusion_coeff=1.0, start_pos=start_pos)\n",
    "                traj.label = \"mobile_particle\"\n",
    "            else:\n",
    "                traj = generate_subdiffusive_trajectory(n_frames, dt=dt, alpha=0.75, start_pos=start_pos)\n",
    "                traj.label = \"confined_particle\"\n",
    "            traj.particle_id = i\n",
    "            trajectories.append(traj)\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "\nprint(\"✓ Synthetic data generators ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Run Analysis on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 1: Colloidal System (Brownian, No Heterogeneity)\n",
    "# ============================================================================\n",
    "\nprint(\"=\"*70)\nprint(\"EXAMPLE 1: Colloidal System\")\nprint(\"=\"*70)\n",
    "\n# Generate ensemble\ntrajectories_colloidal = generate_ensemble(n_particles=10, n_frames=500, dt=0.01, domain=\"colloidal\")\n\nprint(f\"Generated {len(trajectories_colloidal)} colloidal bead trajectories\")\nprint(f\"Mean trajectory length: {np.mean([len(t.t) for t in trajectories_colloidal]):.0f} frames\")\n\n# Initialize analyzer\nanalyzer_colloidal = PhysicsAnalyst(dt=0.01, px_to_um=0.065, wall_z_threshold=2.0)\n\n# Run full analysis\nsummary_colloidal = analyzer_colloidal.summarize_physics(trajectories_colloidal, domain=\"colloidal\")\n\n# Print key results\nprint(f\"\\nBulk MSD Analysis:\")\nprint(f\"  - Anomaly exponent (α): {summary_colloidal['msd_analysis']['bulk']['anomaly_exponent_alpha']:.3f}\")\nprint(f\"  - Diffusion coeff: {summary_colloidal['msd_analysis']['bulk']['diffusion_coefficient']:.3e}\")\nprint(f\"  - Interpretation: {summary_colloidal['msd_analysis']['bulk']['interpretation']}\")\n\nprint(f\"\\nHeterogeneity Metrics:\")\nprint(f\"  - α₂ max: {summary_colloidal['heterogeneity']['alpha2_max']}\")\nprint(f\"  - Subdiffusion detected: {summary_colloidal['heterogeneity']['subdiffusion_detected']}\")\nprint(f\"  - Dynamic susceptibility: {summary_colloidal['heterogeneity']['dynamic_susceptibility']}\")\n\nprint(f\"\\nStructure Analysis:\")\nprint(f\"  - Clustering detected: {summary_colloidal['structure']['clustering_detected']}\")\nprint(f\"  - Number of q-values: {len(summary_colloidal['structure']['q_values'])}\")\n\nprint(f\"\\nFlags/Anomalies:\")\nfor flag in summary_colloidal['flags_and_anomalies']:\n    print(f\"  - {flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 2: Cellular System (Subdiffusion + Heterogeneity)\n",
    "# ============================================================================\n",
    "\nprint(\"\\n\" + \"=\"*70)\nprint(\"EXAMPLE 2: Cellular System\")\nprint(\"=\"*70)\n",
    "\ntrajectories_cellular = generate_ensemble(n_particles=15, n_frames=500, dt=0.01, domain=\"cellular\")\n\nprint(f\"Generated {len(trajectories_cellular)} cellular trajectories (nuclei + vesicles)\")\n\nanalyzer_cellular = PhysicsAnalyst(dt=0.01, px_to_um=0.065, wall_z_threshold=2.0)\nsummary_cellular = analyzer_cellular.summarize_physics(trajectories_cellular, domain=\"cellular\")\n\nprint(f\"\\nBulk MSD Analysis:\")\nprint(f\"  - Anomaly exponent (α): {summary_cellular['msd_analysis']['bulk']['anomaly_exponent_alpha']:.3f}\")\nprint(f\"  - Interpretation: {summary_cellular['msd_analysis']['bulk']['interpretation']}\")\n\nprint(f\"\\nHeterogeneity Metrics:\")\nprint(f\"  - α₂ max: {summary_cellular['heterogeneity']['alpha2_max']}\")\nprint(f\"  - Subdiffusion detected: {summary_cellular['heterogeneity']['subdiffusion_detected']}\")\nprint(f\"  - MSD distribution std: {summary_cellular['heterogeneity']['msd_distribution_std']}\")\n\nprint(f\"\\nFlags/Anomalies:\")\nfor flag in summary_cellular['flags_and_anomalies']:\n    print(f\"  - {flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 3: Polymer System (Strong Subdiffusion + Heterogeneity)\n",
    "# ============================================================================\n",
    "\nprint(\"\\n\" + \"=\"*70)\nprint(\"EXAMPLE 3: Polymer System\")\nprint(\"=\"*70)\n",
    "\ntrajectories_polymer = generate_ensemble(n_particles=12, n_frames=500, dt=0.01, domain=\"polymer\")\n\nprint(f\"Generated {len(trajectories_polymer)} polymer bead trajectories\")\n\nanalyzer_polymer = PhysicsAnalyst(dt=0.01, px_to_um=0.065, wall_z_threshold=2.0)\nsummary_polymer = analyzer_polymer.summarize_physics(trajectories_polymer, domain=\"polymer\")\n\nprint(f\"\\nBulk MSD Analysis:\")\nprint(f\"  - Anomaly exponent (α): {summary_polymer['msd_analysis']['bulk']['anomaly_exponent_alpha']:.3f}\")\nprint(f\"  - Interpretation: {summary_polymer['msd_analysis']['bulk']['interpretation']}\")\n\nprint(f\"\\nHeterogeneity Metrics:\")\nprint(f\"  - α₂ max: {summary_polymer['heterogeneity']['alpha2_max']}\")\nprint(f\"  - Dynamic susceptibility: {summary_polymer['heterogeneity']['dynamic_susceptibility']}\")\n\nprint(f\"\\nFlags/Anomalies:\")\nfor flag in summary_polymer['flags_and_anomalies']:\n    print(f\"  - {flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Visualization and Interpretation\n",
    "\n",
    "Plot all four diagnostic categories side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagnostics(analyzer: PhysicsAnalyst, \n",
    "                    trajectories: List[Trajectory],\n",
    "                    summary: Dict,\n",
    "                    title: str = \"Physics Diagnostics\"):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of all four diagnostic modules.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # ====== Panel 1: Bulk + Wall + Cage MSD ======\n",
    "    ax = axes[0, 0]\n",
    "    \n",
    "    bulk = summary['msd_analysis']['bulk']\n",
    "    wall = summary['msd_analysis']['near_wall']\n",
    "    cage = summary['msd_analysis']['cage_relative']\n",
    "    \n",
    "    ax.loglog(bulk['lag_times'], bulk['msd_values'], 'o-', label='Bulk MSD', linewidth=2, markersize=6)\n",
    "    ax.loglog(wall['lag_times'], wall['msd_wall'], 's--', label='Near-wall MSD', linewidth=2, markersize=5, alpha=0.7)\n",
    "    ax.loglog(cage['lag_times'], cage['msd_cage'], '^:', label='Cage-relative MSD', linewidth=2, markersize=5, alpha=0.7)\n",
    "    \n",
    "    # Overlay power law fit\n",
    "    alpha = bulk['anomaly_exponent_alpha']\n",
    "    tau_fit = np.array(bulk['lag_times'])[1:10]\n",
    "    msd_fit = tau_fit ** alpha * (bulk['msd_values'][5] / (tau_fit[3]**alpha))\n",
    "    ax.loglog(tau_fit, msd_fit, 'k--', alpha=0.5, label=f\"α={alpha:.2f}\")\n",
    "    \n",
    "    ax.set_xlabel('Lag time (physical units)', fontsize=11)\n",
    "    ax.set_ylabel('MSD (μm²)', fontsize=11)\n",
    "    ax.set_title('1. MSD Analysis: Bulk, Wall, and Cage-Relative', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, which='both', alpha=0.3)\n",
    "    \n",
    "    # ====== Panel 2: Non-Gaussian Parameter α₂(τ) ======\n",
    "    ax = axes[0, 1]\n",
    "    \n",
    "    lag_times_het, alpha2_array = analyzer.compute_non_gaussian_parameter(trajectories)\n",
    "    \n",
    "    ax.plot(lag_times_het, alpha2_array, 'o-', color='tab:red', linewidth=2, markersize=6, label='α₂(τ)')\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.5, label='Gaussian threshold')\n",
    "    ax.fill_between(lag_times_het, 0, alpha2_array, alpha=0.3, color='tab:red')\n",
    "    \n",
    "    hetero = summary['heterogeneity']\n",
    "    if hetero['alpha2_max']:\n",
    "        ax.plot(hetero['alpha2_tau_peak'], hetero['alpha2_max'], 'r*', markersize=20, \n",
    "               label=f\"Peak α₂={hetero['alpha2_max']:.3f}\")\n",
    "    \n",
    "    ax.set_xlabel('Lag time (physical units)', fontsize=11)\n",
    "    ax.set_ylabel('Non-Gaussian Parameter α₂(τ)', fontsize=11)\n",
    "    ax.set_title('2. Heterogeneity: Non-Gaussian Dynamics', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ====== Panel 3: Structure Factor S(q) ======\n",
    "    ax = axes[1, 0]\n",
    "    \n",
    "    struct = summary['structure']\n",
    "    ax.plot(struct['q_values'], struct['structure_factor'], 'o-', color='tab:green', linewidth=2, markersize=6)\n",
    "    ax.axhline(y=1, color='k', linestyle='--', alpha=0.5, label='Random distribution')\n",
    "    ax.fill_between(struct['q_values'], 1, struct['structure_factor'], alpha=0.3, color='tab:green')\n",
    "    \n",
    "    ax.set_xlabel('Wave vector q (1/μm)', fontsize=11)\n",
    "    ax.set_ylabel('Structure Factor S(q)', fontsize=11)\n",
    "    ax.set_title('3. Structure Analysis: Static Structure Factor', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ====== Panel 4: Pair Correlation g(r) ======\n",
    "    ax = axes[1, 1]\n",
    "    \n",
    "    if struct['pair_correlation'] and struct['distances']:\n",
    "        ax.plot(struct['distances'], struct['pair_correlation'], 'o-', color='tab:purple', linewidth=2, markersize=6)\n",
    "        ax.axhline(y=1, color='k', linestyle='--', alpha=0.5, label='Random distribution')\n",
    "        ax.fill_between(struct['distances'], 1, struct['pair_correlation'], alpha=0.3, color='tab:purple')\n",
    "        \n",
    "        ax.set_xlabel('Pairwise distance (μm)', fontsize=11)\n",
    "        ax.set_ylabel('Radial Distribution Function g(r)', fontsize=11)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"Insufficient data for g(r)\", ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    ax.set_title('4. Structure Analysis: Radial Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n\n# Plot all three examples\nfig1 = plot_diagnostics(analyzer_colloidal, trajectories_colloidal, summary_colloidal, \"Colloidal System Diagnostics\")\nplt.show()\n\nfig2 = plot_diagnostics(analyzer_cellular, trajectories_cellular, summary_cellular, \"Cellular System Diagnostics\")\nplt.show()\n\nfig3 = plot_diagnostics(analyzer_polymer, trajectories_polymer, summary_polymer, \"Polymer System Diagnostics\")\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: JSON Export for LLM Integration\n",
    "\n",
    "Save summaries as JSON files ready for use by ChatGPT/Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\nfrom pathlib import Path\n\n# Create output directory\noutput_dir = Path(\"physics_summaries\")\noutput_dir.mkdir(exist_ok=True)\n\n# Save summaries\nfor name, summary in [(\"colloidal\", summary_colloidal),\n                      (\"cellular\", summary_cellular),\n                      (\"polymer\", summary_polymer)]:\n    output_file = output_dir / f\"{name}_summary.json\"\n    with open(output_file, 'w') as f:\n        json.dump(summary, f, indent=2)\n    print(f\"✓ Saved: {output_file}\")\n\nprint(f\"\\nAll summaries saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: LLM-Ready Summary Format\n",
    "\n",
    "Example prompt for ChatGPT/Gemini that uses the JSON summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompt(summary: Dict, domain: str = \"general\") -> str:\n",
    "    \"\"\"\n",
    "    Create a structured prompt for LLM explainer using physics summary.\n",
    "    \n",
    "    This prompt can be sent to ChatGPT 4, Gemini Pro, or Claude.\n",
    "    \"\"\"\n",
    "    \n",
    "    bulk = summary['msd_analysis']['bulk']\n",
    "    hetero = summary['heterogeneity']\n",
    "    struct = summary['structure']\n",
    "    flags = summary['flags_and_anomalies']\n",
    "    \n",
    "    prompt = f\"\"\"\n## Confocal Microscopy Physics Analysis Report\n\n**Domain:** {domain.title()}\n**Number of Trajectories:** {summary['metadata']['n_trajectories']}\n**Physical Parameters:** dt = {summary['metadata']['dt_physical_units']}, px_to_um = {summary['metadata']['px_to_um_conversion']}\n\n### Key Findings\n\n**1. Diffusion Dynamics (MSD Analysis)**\n- Anomaly exponent (α): **{bulk['anomaly_exponent_alpha']:.3f}**\n- Interpretation: {bulk['interpretation']}\n- Diffusion coefficient: {bulk['diffusion_coefficient']:.3e}\n\n**2. Heterogeneity Metrics**\n- Non-Gaussian parameter (α₂) maximum: {hetero['alpha2_max']}\n- Peak non-Gaussian lag time: {hetero['alpha2_tau_peak']}\n- MSD distribution std: {hetero['msd_distribution_std']}\n- MSD distribution mean: {hetero['msd_distribution_mean']}\n- Subdiffusion detected: {hetero['subdiffusion_detected']}\n- Superdiffusion detected: {hetero['superdiffusion_detected']}\n- Dynamic susceptibility (variance proxy): {hetero['dynamic_susceptibility']}\n\n**3. Structure Analysis**\n- Clustering detected (S(0) >> 1): {struct['clustering_detected']}\n- System density: {struct['density']}\n- Number of measured q-vectors: {len(struct['q_values'])}\n\n**4. Anomalies & Flags**\n\"\"\"\n    \n    for i, flag in enumerate(flags, 1):\n        prompt += f\"- {flag}\\n\"\n    \n    prompt += f\"\"\"\n### Domain-Specific Interpretation\n\n\"\"\"\n    \n    if domain.lower() == \"colloidal\":\n        prompt += \"\"\"In the **colloidal context**, these measurements suggest:\n- Brownian motion (α ≈ 1) indicates free diffusion without confinement\n- Low heterogeneity (α₂ small) is consistent with hard-sphere dynamics\n- Structure factor S(q) reveals packing statistics and possible gel formation\n\nNext steps: Check for gelation, measure interaction potentials, or examine shear response.\n\"\"\"\n    \n    elif domain.lower() == \"cellular\":\n        prompt += \"\"\"In the **cellular context**, these measurements suggest:\n- Subdiffusion (α < 1) is typical for nuclear/cytoplasmic diffusion due to crowding\n- High heterogeneity (α₂ large) may indicate coexistence of mobile and immobile pools\n- Clustering in structure factor could reflect organelle co-localization\n\nNext steps: Segment mobile vs. immobile pools, quantify crowding, or map spatial domains.\n\"\"\"\n    \n    elif domain.lower() == \"polymer\":\n        prompt += \"\"\"In the **polymer context**, these measurements suggest:\n- Strong subdiffusion (α << 1) is characteristic of monomer dynamics in entangled chains\n- High non-Gaussian parameter reflects local chain rearrangements\n- MSD heterogeneity arises from intra-chain friction and excluded volume\n\nNext steps: Characterize chain relaxation, compute entanglement length, or measure viscoelasticity.\n\"\"\"\n    \n    else:\n        prompt += \"\"\"General interpretation:\n- Compare α to 1.0 to assess whether dynamics are normal (Brownian), subdiffusive, or superdiffusive\n- Use heterogeneity metrics to detect dynamic heterogeneity and non-equilibrium effects\n- Structure factors reveal spatial correlations and clustering tendencies\n\"\"\"\n    \n    prompt += f\"\"\"\n\n### JSON Summary (for programmatic use)\n\n```json\n{json.dumps(summary, indent=2)}\n```\n\"\"\"\n    \n    return prompt\n\n\n# Generate and display example prompts\nprint(\"=\"*70)\nprint(\"LLM PROMPT FOR COLLOIDAL SYSTEM\")\nprint(\"=\"*70)\nprompt_colloidal = create_llm_prompt(summary_colloidal, domain=\"colloidal\")\nprint(prompt_colloidal[:1000] + \"\\n... [truncated for display]\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"LLM PROMPT FOR CELLULAR SYSTEM\")\nprint(\"=\"*70)\nprompt_cellular = create_llm_prompt(summary_cellular, domain=\"cellular\")\nprint(prompt_cellular[:1000] + \"\\n... [truncated for display]\")\n\n# Save prompts\nwith open(output_dir / \"colloidal_llm_prompt.txt\", 'w') as f:\n    f.write(prompt_colloidal)\nwith open(output_dir / \"cellular_llm_prompt.txt\", 'w') as f:\n    f.write(prompt_cellular)\nwith open(output_dir / \"polymer_llm_prompt.txt\", 'w') as f:\n    f.write(create_llm_prompt(summary_polymer, domain=\"polymer\"))\n\nprint(f\"\\n✓ All LLM prompts saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Integration Guide\n",
    "\n",
    "How to integrate `PhysicsAnalyst` into your existing copilot codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Integration\n",
    "\n",
    "#### 1. Copy to your codebase\n",
    "\n",
    "```bash\n# In your confocal_microscopy-copilot repo\ncp physics_analyst_advanced.py src/analysis/physics_analyst_advanced.py\n```\n",
    "\n",
    "#### 2. Update DetectionTrackingWorker to produce Trajectory objects\n",
    "\n",
    "```python\n# src/tracking/detection_tracking_worker.py\nfrom src.analysis.physics_analyst_advanced import Trajectory\n\nclass DetectionTrackingWorker:\n    def get_trajectories(self) -> List[Trajectory]:\n        \"\"\"Export linked trajectories as Trajectory objects.\"\"\"\n        trajectories = []\n        for track_id, positions in self.tracks.items():\n            traj = Trajectory(\n                particle_id=track_id,\n                t=positions['t'],\n                x=positions['x'],\n                y=positions['y'],\n                z=positions['z'],\n                confidence=positions.get('confidence'),\n                radius=positions.get('radius', 0.5),\n                label=positions.get('label', 'particle')\n            )\n            trajectories.append(traj)\n        return trajectories\n```\n\n#### 3. Integrate PhysicsAnalyst into your main pipeline\n\n```python\n# src/app.py or main.py\nfrom src.analysis.physics_analyst_advanced import PhysicsAnalyst\n\nclass MicroscopyAnalysisPipeline:\n    def __init__(self, domain: str = \"general\"):\n        self.detector = DetectionTrackingWorker(...)\n        self.physics = PhysicsAnalyst(\n            dt=0.016,  # 16ms per frame for 60Hz camera\n            px_to_um=0.065,  # 65 nm per pixel\n            wall_z_threshold=2.0  # 2 um from substrate\n        )\n        self.domain = domain\n    \n    def analyze(self):\n        # Get trajectories from detector\n        trajectories = self.detector.get_trajectories()\n        \n        # Run physics analysis\n        summary = self.physics.summarize_physics(trajectories, domain=self.domain)\n        \n        # Return JSON for UI/LLM\n        return summary\n```\n\n#### 4. Connect to your LLM explainer\n\n```python\n# src/llm/chat_explainer.py\nfrom src.analysis.physics_analyst_advanced import create_llm_prompt\nimport openai\n\nclass LLMExplainer:\n    def explain(self, physics_summary: Dict) -> str:\n        \"\"\"Generate explanation using ChatGPT.\"\"\"\n        \n        # Create prompt from physics summary\n        prompt = create_llm_prompt(physics_summary, domain=\"cellular\")\n        \n        # Send to OpenAI\n        response = openai.ChatCompletion.create(\n            model=\"gpt-4\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an expert in microscopy physics and soft matter dynamics.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.7,\n            max_tokens=1024\n        )\n        \n        return response['choices'][0]['message']['content']\n```\n\n#### 5. Expose in UI\n\n```html\n<!-- ui/components/physics_dashboard.html -->\n<div id=\"diagnostics-container\">\n  <div id=\"msd-plots\"></div>\n  <div id=\"heterogeneity-metrics\"></div>\n  <div id=\"structure-analysis\"></div>\n  <button id=\"ask-llm\">Ask LLM for Explanation</button>\n  <div id=\"llm-explanation\"></div>\n</div>\n\n<script>\n  // Fetch physics summary from backend\n  fetch('/api/physics-analysis')\n    .then(r => r.json())\n    .then(summary => {\n      renderMSDPlots(summary.msd_analysis);\n      renderHeterogeneityMetrics(summary.heterogeneity);\n      renderStructureAnalysis(summary.structure);\n      \n      // LLM button\n      document.getElementById('ask-llm').onclick = () => {\n        fetch('/api/explain-physics', {\n          method: 'POST',\n          body: JSON.stringify(summary)\n        })\n        .then(r => r.json())\n        .then(data => {\n          document.getElementById('llm-explanation').innerText = data.explanation;\n        });\n      };\n    });\n</script>\n```\n\n### Configuration Schema (YAML)\n\nCreate a config file for different microscopy setups:\n\n```yaml\n# configs/confocal_setups.yaml\n\nsetups:\n  zeiss_lsm:\n    dt_ms: 5.0\n    px_to_um: 0.032  # 32 nm pixels\n    pinhole_um: 0.5\n    wall_threshold_um: 1.5\n    domain: \"colloidal\"\n  \n  nikon_a1:\n    dt_ms: 10.0\n    px_to_um: 0.065\n    pinhole_um: 1.0\n    wall_threshold_um: 2.0\n    domain: \"general\"\n  \n  live_cell_imaging:\n    dt_ms: 100.0  # slower, thermal drift\n    px_to_um: 0.1\n    pinhole_um: 2.0\n    wall_threshold_um: 5.0\n    domain: \"cellular\"\n```\n\nLoad and use:\n\n```python\nimport yaml\n\nwith open('configs/confocal_setups.yaml', 'r') as f:\n    setups = yaml.safe_load(f)['setups']\n\nconfig = setups['nikon_a1']\nanalyzer = PhysicsAnalyst(\n    dt=config['dt_ms'] / 1000,\n    px_to_um=config['px_to_um'],\n    wall_z_threshold=config['wall_threshold_um']\n)\n```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Advanced Topics & Extensions\n",
    "\n",
    "Future enhancements and research directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Time-Dependent Heterogeneity\n",
    "\n",
    "Track how dynamics evolve in time (e.g., sample aging, aging in glassy systems):\n",
    "\n",
    "```python\ndef compute_age_dependent_msd(trajectories, age_windows=5):\n    \"\"\"Compute MSD in temporal blocks to reveal aging.\"\"\"\n    # Divide trajectory into age_windows temporal slices\n    # Compute MSD in each slice\n    # Plot as heatmap: lag_time vs age\n```\n\n### B. Flow-Induced Dynamics\n\nFor shear or pressure-driven systems:\n\n```python\ndef compute_velocity_autocorrelation(trajectories):\n    \"\"\"Compute v(t) · v(0) to detect flow alignment.\"\"\"\n    # For each particle, compute velocity vectors\n    # Autocorrelate to detect flow direction\n```\n\n### C. Machine Learning for Domain Classification\n\nTrain a classifier to automatically assign domain type from physics metrics:\n\n```python\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Training data: (alpha, alpha2_max, dynamic_susceptibility) -> domain label\nX = np.array([...])\ny = np.array([...])\n\nclf = RandomForestClassifier()\nclf.fit(X, y)\n\ndef auto_classify_domain(summary):\n    features = np.array([[\n        summary['msd_analysis']['bulk']['anomaly_exponent_alpha'],\n        summary['heterogeneity']['alpha2_max'],\n        summary['heterogeneity']['dynamic_susceptibility']\n    ]])\n    return clf.predict(features)[0]\n```\n\n### D. Interactive LLM Feedback Loop\n",
    "\n```python\nclass InteractiveLLMExplainer:\n    def __init__(self, model=\"gpt-4\"):\n        self.model = model\n        self.conversation_history = []\n    \n    def explain_and_refine(self, physics_summary, follow_up_questions):\n        \"\"\"Multi-turn conversation for deeper insights.\"\"\"\n        # Initial explanation\n        prompt = create_llm_prompt(physics_summary)\n        initial_response = self.query_llm(prompt)\n        self.conversation_history.append((\"system\", prompt, initial_response))\n        \n        # Follow-up questions\n        for question in follow_up_questions:\n            follow_up_prompt = f\"\"\"\n            Based on the previous analysis, {question}\n            \n            Physics context:\n            {json.dumps(physics_summary, indent=2)}\n            \"\"\"\n            response = self.query_llm(follow_up_prompt)\n            self.conversation_history.append((\"user\", follow_up_prompt, response))\n        \n        return self.conversation_history\n```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Best Practices & Troubleshooting\n",
    "\n",
    "### Common Issues & Solutions\n",
    "\n",
    "| Issue | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| α2 always zero | No displacement variance | Check trajectory quality; ensure sufficient time steps |\n",
    "| S(q) >> 1 everywhere | Random q-vector sampling | Use regular q-grid or average over multiple directions |\n",
    "| g(r) noisy | Too few particles | Increase ensemble size or smooth with rolling window |\n",
    "| Wall MSD = Bulk MSD | No particles near wall | Increase wall_z_threshold or check z-calibration |\n",
    "| Negative MSD values | Numerical error | Check for NaN in positions; use `np.maximum(..., 1e-10)` |\n",
    "| LLM output generic | Poor context in prompt | Include domain, n_particles, alpha2_max in system prompt |\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Use stride parameter** to reduce computation:\n",
    "   ```python\n",
    "   lag_times, msd = analyzer.compute_msd(traj, stride=2)  # Skip every other lag\n",
    "   ```\n",
    "\n",
    "2. **Limit trajectory length** for real-time analysis:\n",
    "   ```python\n",
    "   analyzer.compute_msd(traj, max_lag_frames=100)  # Cap at 100 frames\n",
    "   ```\n",
    "\n",
    "3. **Cache structure factors** for repeated queries:\n",
    "   ```python\n",
    "   cache = {}\n",
    "   if hash(trajectories) not in cache:\n",
    "       cache[hash(trajectories)] = analyzer.compute_structure_analysis(trajectories)\n",
    "   ```\n",
    "\n",
    "### Validation Checklist\n",
    "\n",
    "- [ ] MSD increases monotonically with lag time\n",
    "- [ ] α ≈ 1 for known Brownian particles\n",
    "- [ ] α2(0) = 0 and α2 increases then decreases\n",
    "- [ ] S(q→0) > 1 for real systems (compressibility)\n",
    "- [ ] g(r) ≈ 1 at large r (bulk random)\n",
    "- [ ] Flags are actionable and domain-specific\n",
    "- [ ] LLM explanations cite specific values from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: References & Further Reading\n",
    "\n",
    "### Key Physics Papers\n",
    "\n",
    "1. **MSD and Anomaly Exponents:**\n",
    "   - Wang et al. (2012). \"Anomalous yet Brownian.\" PNAS 109(20):7641-7646\n",
    "   - Metzler & Klafter (2000). \"The random walk's guide to anomalous diffusion.\" PhysRep 339(1):1-77\n",
    "\n",
    "2. **Non-Gaussian Parameter α₂:**\n",
    "   - Chubynsky & Slater (2005). \"Diffusing diffusivity: a model for anomalous diffusion.\" PRL 113(10):098302\n",
    "\n",
    "3. **Structure Factors:**\n",
    "   - Hansen & McDonald (2013). *Theory of Simple Liquids* (Ch. 4)\n",
    "\n",
    "4. **Confocal Microscopy PSF:**\n",
    "   - Gibson & Lanni (1992). \"Experimental test of an analytical model.\" JOSA 9(1):154-166\n",
    "\n",
    "### Tools & Software\n",
    "\n",
    "- **TrackPy**: Python particle tracking library (http://soft-matter.github.io/trackpy/)\n",
    "- **DeepTrack 2**: Deep learning for microscopy (http://DeepTrack.itu.dk)\n",
    "- **Huygens PSF Generator**: Realistic PSF simulations (https://svi.nl)\n",
    "- **GROMACS/LAMMPS**: MD simulation reference (for validating physics)\n",
    "\n",
    "### LLM Best Practices\n",
    "\n",
    "- Keep JSON summaries <4000 tokens to avoid token limits\n",
    "- Use clear field names (\"anomaly_exponent_alpha\" > \"a\")\n",
    "- Include units in all scalar values\n",
    "- Provide domain context in system prompt\n",
    "- Request structured output (bullet points, JSON) from LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What You've Learned\n",
    "\n",
    "### ✓ Completed\n",
    "\n",
    "1. **Implemented PhysicsAnalyst class** with all four diagnostic modules:\n",
    "   - Bulk MSD with power-law fitting (anomaly exponent α)\n",
    "   - Near-wall MSD revealing surface-induced hindrance\n",
    "   - Cage-relative MSD isolating local rearrangements\n",
    "   - Heterogeneity metrics (α₂, dynamic susceptibility)\n",
    "   - Structure functions (S(q) and g(r))\n",
    "\n",
    "2. **Domain-agnostic design:**\n",
    "   - Works for colloidal, cellular, polymer, and mixed systems\n",
    "   - Configurable physical parameters (dt, px_to_um, wall_threshold)\n",
    "   - Domain-aware flag generation\n",
    "\n",
    "3. **LLM-ready JSON export:**\n",
    "   - Structured summaries with all metrics\n",
    "   - Example prompts for ChatGPT/Gemini\n",
    "   - Integration guide for your existing codebase\n",
    "\n",
    "4. **Visualizations:**\n",
    "   - 4-panel diagnostic plots\n",
    "   - Log-log MSD with power-law overlay\n",
    "   - Non-Gaussian parameter vs lag time\n",
    "   - Structure factor and pair correlation functions\n",
    "\n",
    "### → Next Steps for Your Hackathon\n",
    "\n",
    "1. **Integrate PhysicsAnalyst into DetectionTrackingWorker**\n",
    "   - Convert linked trajectories to `Trajectory` objects\n",
    "   - Test on real confocal data from your dataset\n",
    "\n",
    "2. **Connect to LLM explainer**\n",
    "   - Replace dummy explainer with real OpenAI/Gemini client\n",
    "   - Test multi-turn conversation for follow-up questions\n",
    "\n",
    "3. **Add UI elements**\n",
    "   - Render MSD plots and metrics in dashboard\n",
    "   - Add \"Ask LLM\" button with streaming response\n",
    "   - Toggle between domain contexts\n",
    "\n",
    "4. **Extend with real digital twin**\n",
    "   - Replace synthetic trajectories with digital-twin-generated data\n",
    "   - Validate against known physics (Stokes drag, viscoelasticity)\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your hackathon! 🚀**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
